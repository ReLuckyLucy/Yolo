
<div align="center">
  <img alt="logo" height="200px" src="img\logo.png">
</div>

# **Yolo 框架整合**

## 💫 环境下载

### **使用 pip 安装**

使用 `pip` 安装 Ultralytics，请执行以下命令：
```bash
pip install ultralytics
```

或者，您可以直接从 GitHub 安装最新的开发版本：
```bash
pip install git+https://github.com/ultralytics/ultralytics.git
```

### **使用 conda 安装**

使用 `conda` 安装 Ultralytics YOLO：
```bash
conda install -c conda-forge ultralytics
```

**此方法是 pip 的绝佳替代方案，可确保与环境中的其他包兼容。对于 CUDA 环境，最好安装以下包，并同时解决任何冲突：**  
`ultralytics`, `pytorch`, `pytorch-cuda`

```bash
conda install -c pytorch -c nvidia -c conda-forge pytorch torchvision pytorch-cuda=11.8 ultralytics
```

### **源码编译**

克隆 Ultralytics 存储库并设置开发环境：
```bash
# 克隆 ultralytics 存储库
git clone https://github.com/ultralytics/ultralytics

# 进入克隆目录
cd ultralytics

# 以可编辑模式安装包用于开发
pip install -e .
```

---

## ✍️ **训练**

### 使用 CLI

```bash
# 从 YAML 文件构建新模型并从头开始训练
yolo detect train data=coco8.yaml model=yolo11n.yaml epochs=100 imgsz=640

# 从预训练的 *.pt 模型开始训练
yolo detect train data=coco8.yaml model=yolo11n.pt epochs=100 imgsz=640

# 从 YAML 文件构建新模型，转移预训练权重并开始训练
yolo detect train data=coco8.yaml model=yolo11n.yaml pretrained=yolo11n.pt epochs=100 imgsz=640
```

### 使用 Python

```python
from ultralytics import YOLO

# 加载一个模型
model = YOLO("yolo11n.yaml")  # 从 YAML 构建新模型
model = YOLO("yolo11n.pt")    # 加载一个预训练模型（推荐用于训练）
model = YOLO("yolo11n.yaml").load("yolo11n.pt")  # 从 YAML 构建并转移权重

# 训练模型
results = model.train(data="coco8.yaml", epochs=100, imgsz=640)
```

---

## 🎃 **验证**

在训练后验证 YOLO 模型。此模式会在验证集上评估模型，以测量其准确性和泛化性能。可以通过该模式调整超参数来提高模型性能。

```python
from ultralytics import YOLO

# 加载 YOLO 模型
model = YOLO("yolo11n.yaml")

# 训练模型
model.train(data="coco8.yaml", epochs=5)

# 在训练数据上验证
model.val()
```

使用其他验证集进行评估：

```python
from ultralytics import YOLO

# 加载 YOLO 模型
model = YOLO("yolo11n.yaml")

# 训练模型
model.train(data="coco8.yaml", epochs=5)

# 使用分离的数据进行验证
model.val(data="path/to/separate/data.yaml")
```

---

## 🔮 **预测**

使用经过训练的 YOLO 模型对新图像或视频进行预测。在此模式下，模型会从检查点文件加载，用户可以提供图像或视频进行推理，模型会预测输入中的对象类别和位置。

```python
import cv2
from PIL import Image

from ultralytics import YOLO

model = YOLO("model.pt")

# 接受所有格式 - 图像/目录/路径/URL/视频/PIL/ndarray，0 表示摄像头
results = model.predict(source="0")

# 从文件夹中进行预测，显示结果
results = model.predict(source="folder", show=True)

# 从 PIL 图像进行预测
im1 = Image.open("bus.jpg")
results = model.predict(source=im1, save=True)  # 保存标注后的图像

# 从 ndarray 图像进行预测
im2 = cv2.imread("bus.jpg")
results = model.predict(source=im2, save=True, save_txt=True)  # 保存预测结果为标签

# 从 PIL/ndarray 图像列表进行预测
results = model.predict(source=[im1, im2])
```

---

## **使用 Comet ML 进行可视化面板**

![This is an Comet](img\Comet.png)

记录关键训练细节（如参数、指标、图像预测和模型检查点）对机器学习项目至关重要，可以保持项目的透明度、可衡量的进度和可重复的结果。

Ultralytics YOLO11 与 Comet ML 无缝集成，有效捕获和优化训练过程中的各个方面。在本指南中，我们将介绍安装过程、Comet ML 设置、实时洞察、自定义日志记录和离线使用，确保 YOLO11 训练过程得到全面记录并优化。

### **安装 Comet ML**

```bash
pip install ultralytics comet_ml torch torchvision
```

安装所需的软件包后，您需要注册并获取 [Comet API Key](https://www.comet.com/signup)，然后配置它。

```bash
export COMET_API_KEY=<Your API Key>
```

> **警告**: `export` 是 Linux 命令，在 Windows 上执行时需选择以下两种方式：
> + 临时设置 API 密钥
> + 永久设置 API 密钥

### **在 Windows 中设置 `COMET_API_KEY`**

1. **临时设置 API 密钥**：
   在命令行中使用 `set` 命令临时设置环境变量：
   ```bash
   set COMET_API_KEY=BV7SlLzug7TSvVqv4PMmFNpCT
   ```

2. **永久设置 API 密钥**：
   - 打开环境变量设置：
     1. 右键点击“此电脑”（或“我的电脑”），选择“属性”。
     2. 点击“高级系统设置”。
     3. 在“系统属性”窗口中，点击“环境变量”。
   - 添加新的系统环境变量：
     1. 在“环境变量”窗口中，点击“新建”。
     2. 设置变量名为 `COMET_API_KEY`，变量值为您的 API 密钥。
   - 保存设置并关闭窗口。

3. **验证 API 密钥是否生效**：
   在命令行中运行以下命令来检查 Comet ML 是否能够成功识别您的 API 密钥：
   ```bash
   comet-cli check
   ```

### **使用 Comet ML 登录**

一旦 API 密钥设置完成，您可以通过以下命令登录 Comet ML：

```bash
comet login
```

如果环境变量已经正确配置，应该无需再次输入 API 密钥。

---

## **ReLucy 运行代码**

运行训练代码
```bash
python train.py
```

---

## ⚠️ **警告**

1. **路径问题**：大多数错误通常与路径设置相关。
2. **训练速度慢/设备参数问题**：若在使用 `DEVICE = "0"` 参数时遇到报错，通常是因为 PyTorch 版本不匹配。可以运行以下代码进行测试：
```bash
python pytorch_test.py
```


