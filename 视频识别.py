import gradio as gr
import cv2
import numpy as np
from ultralytics import YOLO
import os
import time
import json
import tempfile

def save_results_to_json(results, output_path):
    detection_data = []
    for result in results:
        if not hasattr(result, 'boxes') or result.boxes is None:
            continue
        boxes = result.boxes
        for i, box in enumerate(boxes):
            try:
                class_idx = int(box.cls[0]) if len(box.cls) > 0 else 0
                class_name = result.names[class_idx] if class_idx in result.names else "unknown"
                confidence = float(box.conf[0]) if len(box.conf) > 0 else 0.0
                if hasattr(box, 'xyxy') and box.xyxy is not None and len(box.xyxy) > 0:
                    xyxy = box.xyxy[0]
                    x1 = float(xyxy[0]) if len(xyxy) > 0 else 0.0
                    y1 = float(xyxy[1]) if len(xyxy) > 1 else 0.0
                    x2 = float(xyxy[2]) if len(xyxy) > 2 else 0.0
                    y2 = float(xyxy[3]) if len(xyxy) > 3 else 0.0
                else:
                    x1, y1, x2, y2 = 0.0, 0.0, 0.0, 0.0
                detection = {
                    "class": class_name,
                    "confidence": confidence,
                    "bbox": {
                        "x1": x1,
                        "y1": y1,
                        "x2": x2,
                        "y2": y2
                    }
                }
                detection_data.append(detection)
            except Exception as box_error:
                continue
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(detection_data, f, ensure_ascii=False, indent=2)
        return output_path
    except Exception as e:
        return None

model_mapping = {
    "YOLOv11n": "model/yolo11n.pt",
    "YOLOv11m": "model/yolo11m.pt",
}
yolo_models = list(model_mapping.keys())

def yolo_video_inference(video, model_name, conf_threshold):
    model_path = model_mapping[model_name]
    try:
        model = YOLO(model_path)
        video_path = tempfile.mktemp(suffix=".mp4")
        with open(video_path, "wb") as f:
            with open(video, "rb") as g:
                f.write(g.read())
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        output_video_path = tempfile.mktemp(suffix=".mp4")
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))
        all_results = []
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            frame_results = model.predict(source=frame, conf=conf_threshold)
            annotated_frame = frame_results[0].plot()
            out.write(annotated_frame)
            if len(frame_results[0].boxes) > 0:
                all_results.extend(frame_results)
        cap.release()
        out.release()
        json_path = os.path.join("results", f"video_detection_{int(time.time())}.json")
        save_results_to_json(all_results, json_path)
        return output_video_path, json_path
    except Exception as e:
        return None, None

def app():
    with gr.Blocks(title="YOLOv11ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ¬ YOLOv11 è§†é¢‘ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ")
        gr.Markdown("ä¸Šä¼ è§†é¢‘è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œæ”¯æŒæ¨¡å‹é€‰æ‹©å’Œç½®ä¿¡åº¦è°ƒèŠ‚")
        with gr.Row():
            with gr.Column(scale=1):
                video = gr.Video(label="è¾“å…¥è§†é¢‘")
                yolo_model = gr.Dropdown(
                    label="YOLOæ¨¡å‹é€‰æ‹©",
                    choices=yolo_models,
                    value=yolo_models[0],
                    info="é€‰æ‹©è¦ä½¿ç”¨çš„YOLOv11æ¨¡å‹ç‰ˆæœ¬"
                )
                conf_threshold = gr.Slider(
                    minimum=0.0, maximum=1.0, value=0.25, step=0.05,
                    label="ç½®ä¿¡åº¦é˜ˆå€¼",
                    info="è°ƒæ•´æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè¾ƒä½çš„å€¼ä¼šå¢åŠ æ£€æµ‹æ•°é‡ä½†å¯èƒ½å¢åŠ è¯¯æŠ¥"
                )
                # å•ç‹¬ä¸€è¡Œæœ€å¤§å®½åº¦çš„å¼€å§‹è¯†åˆ«æŒ‰é’®
                start_btn = gr.Button("ğŸš€ å¼€å§‹è¯†åˆ«", variant="primary", scale=2)
                # ä¸‹ä¸€è¡Œå¹¶æ’æ˜¾ç¤ºæ¸…é™¤å’Œç»ˆæ­¢
                with gr.Row():
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤", variant="secondary")
                    stop_btn = gr.Button("â¹ï¸ ç»ˆæ­¢", variant="stop")
            with gr.Column(scale=2):
                output_video = gr.Video(label="æ£€æµ‹ç»“æœ")
                json_output = gr.File(label="æ£€æµ‹ç»“æœJSONæ–‡ä»¶")
        def run_inference(video, yolo_model, conf_threshold):
            if video is None:
                return None, None
            return yolo_video_inference(video, yolo_model, conf_threshold)
        start_btn.click(
            fn=run_inference,
            inputs=[video, yolo_model, conf_threshold],
            outputs=[output_video, json_output],
        )
        def clear_all():
            return None, None
        clear_btn.click(
            fn=clear_all,
            inputs=[],
            outputs=[output_video, json_output]
        )
        def stop_all():
            gr.Info("å·²ç»ˆæ­¢æ¨ç†ä»»åŠ¡ã€‚è¯·åˆ·æ–°é¡µé¢æˆ–é‡æ–°ä¸Šä¼ è§†é¢‘åå†è¯•ã€‚")
            return None, None
        stop_btn.click(
            fn=stop_all,
            inputs=[],
            outputs=[output_video, json_output]
        )
        return demo

if __name__ == '__main__':
    os.makedirs("results", exist_ok=True)
    demo = app()
    demo.launch(
        server_name="127.0.0.1",
        server_port=7864,
        share=False,
    ) 